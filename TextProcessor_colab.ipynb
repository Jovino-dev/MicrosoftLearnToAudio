{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jovino-dev/MicrosoftLearnToAudio/blob/main/TextProcessor_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9c35bdf",
      "metadata": {
        "id": "c9c35bdf"
      },
      "source": [
        "# Audio extraction from Microsoft learn module\n",
        "This notebook allows to convert a full Microsoft learn module to audio"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06c3c23e",
      "metadata": {
        "id": "06c3c23e"
      },
      "source": [
        "## Download and process all units from module\n",
        "This cell download the units, process the text, generates the audios and downloads a zip file with the audio contents.\n",
        "Edit the form values and click the play button at the left"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0730180",
      "metadata": {
        "id": "e0730180"
      },
      "outputs": [],
      "source": [
        "# @title Execution {\"run\":\"auto\",\"vertical-output\":true,\"display-mode\":\"form\"}\n",
        "url = \"https://learn.microsoft.com/es-es/training/modules/introduction-power-platform/\" # @param {\"type\":\"string\"}\n",
        "language = \"es\" # @param [\"es\",\"en\"]\n",
        "speed = 1.2 # @param {\"type\":\"slider\",\"min\":1,\"max\":2,\"step\":0.1}\n",
        "import re\n",
        "from typing import List\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from gtts import gTTS\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "import sys\n",
        "\n",
        "# Define the TextProcessor class for cleaning and structuring text.\n",
        "class TextProcessor:\n",
        "    def __init__(self):\n",
        "        # Patterns to clean text\n",
        "        self.cleanup_patterns = [\n",
        "            # Remove multiple spaces\n",
        "            (r'\\s+', ' '),\n",
        "            # Remove multiple newlines\n",
        "            (r'\\n\\s*\\n\\s*\\n+', '\\n\\n'),\n",
        "            # Clean problematic special characters\n",
        "            (r'[^\\w\\s\\-.,;:!?¡¿áéíóúñüÁÉÍÓÚÑÜ()[\\]\"\\'/]', ''),\n",
        "            # Normalize punctuation\n",
        "            (r'\\.{2,}', '.'),\n",
        "            (r'\\?{2,}', '?'),\n",
        "            (r'!{2,}', '!'),\n",
        "        ]\n",
        "\n",
        "        # Words/phrases to filter (navigation, UI, etc.)\n",
        "        self.filter_phrases = [\n",
        "            'skip to main content', 'breadcrumb navigation', 'table of contents',\n",
        "            'in this article', 'next steps', 'feedback', 'was this page helpful',\n",
        "            'submit and view feedback', 'microsoft learn', 'sign in', 'search',\n",
        "            'browse', 'theme', 'light', 'dark', 'high contrast', 'previous unit',\n",
        "            'next unit', 'completed', 'check your knowledge', 'knowledge check',\n",
        "            # User-specific intro phrases\n",
        "            'leer en ingles', 'agregar', 'agregar al plan', 'logros', 'preguntar a learn', 'completado',\n",
        "            # User-specific outro phrases\n",
        "            'comentarios', 'le ha resultado util esta pagina',\n",
        "            # Time pattern\n",
        "            'minutos'\n",
        "        ]\n",
        "\n",
        "    def clean_and_structure(self, raw_text):\n",
        "        \"\"\"\n",
        "        Cleans and structures the text for audio conversion\n",
        "\n",
        "        Args:\n",
        "            raw_text (str): Unprocessed text\n",
        "\n",
        "        Returns:\n",
        "            str: Clean and structured text\n",
        "        \"\"\"\n",
        "        if not raw_text:\n",
        "            return \"\"\n",
        "\n",
        "        # Limpiar texto básico\n",
        "        text = self._basic_cleanup(raw_text)\n",
        "\n",
        "        # Filtrar contenido no deseado\n",
        "        text = self._filter_unwanted_content(text)\n",
        "\n",
        "        # Estructurar para audio\n",
        "        text = self._structure_for_audio(text)\n",
        "\n",
        "        # Normalizar espaciado\n",
        "        text = self._normalize_spacing(text)\n",
        "\n",
        "        return text.strip()\n",
        "\n",
        "    def _basic_cleanup(self, text):\n",
        "        \"\"\"Basic text cleanup\"\"\"\n",
        "        # Convertir a minúsculas para comparaciones\n",
        "        text_lower = text.lower()\n",
        "\n",
        "        # Aplicar patrones de limpieza\n",
        "        for pattern, replacement in self.cleanup_patterns:\n",
        "            text = re.sub(pattern, replacement, text)\n",
        "\n",
        "        return text\n",
        "\n",
        "    def _filter_unwanted_content(self, text):\n",
        "        \"\"\"Filters unwanted content such as navigation, UI, etc.\"\"\"\n",
        "        lines = text.split('\\n')\n",
        "        filtered_lines = []\n",
        "\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            line_lower = line.lower()\n",
        "\n",
        "            # Filtrar líneas muy cortas o vacías\n",
        "            if len(line) < 3:\n",
        "                continue\n",
        "\n",
        "            # Filtrar frases específicas\n",
        "            should_filter = False\n",
        "            for phrase in self.filter_phrases:\n",
        "                if phrase in line_lower:\n",
        "                    should_filter = True\n",
        "                    break\n",
        "\n",
        "            # Filtrar líneas que parecen navegación o metadatos\n",
        "            if (line_lower.startswith(('http', 'www.', 'mailto:')) or\n",
        "                line_lower.endswith(('min', 'sec', 'hr')) or\n",
        "                re.match(r'^\\d+\\s*(min|sec|hr|minute|second|hour)', line_lower) or\n",
        "                re.match(r'^(step \\d+|unit \\d+|\\d+\\.)$', line_lower)):\n",
        "                should_filter = True\n",
        "\n",
        "            if not should_filter:\n",
        "                filtered_lines.append(line)\n",
        "\n",
        "        return '\\n'.join(filtered_lines)\n",
        "\n",
        "    def _structure_for_audio(self, text):\n",
        "        \"\"\"Structures the text to sound more natural when listening\"\"\"\n",
        "        lines = text.split('\\n')\n",
        "        structured_lines = []\n",
        "\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "\n",
        "            # Agregar pausas después de títulos/encabezados\n",
        "            if self._is_heading(line):\n",
        "                structured_lines.append(f\"{line}.\")\n",
        "                structured_lines.append(\"\")  # Línea vacía para pausa\n",
        "            else:\n",
        "                # Asegurar que las oraciones terminen con puntuación\n",
        "                if line and not line[-1] in '.!?':\n",
        "                    line += '.'\n",
        "                structured_lines.append(line)\n",
        "\n",
        "        return '\\n'.join(structured_lines)\n",
        "\n",
        "    def _is_heading(self, line):\n",
        "        \"\"\"Determines if a line is a heading\"\"\"\n",
        "        # Encabezados suelen ser más cortos y no terminar en puntuación\n",
        "        return (len(line) < 100 and\n",
        "                not line.endswith(('.', '!', '?', ',', ';', ':')) and\n",
        "                (line.isupper() or line.istitle() or\n",
        "                 any(word.isupper() for word in line.split())))\n",
        "\n",
        "    def _normalize_spacing(self, text):\n",
        "        \"\"\"Normalizes text spacing\"\"\"\n",
        "        # Eliminar espacios extra\n",
        "        text = re.sub(r' +', ' ', text)\n",
        "\n",
        "        # Normalizar saltos de línea\n",
        "        text = re.sub(r'\\n\\s*\\n\\s*\\n+', '\\n\\n', text)\n",
        "\n",
        "        # Eliminar espacios al inicio y final de líneas\n",
        "        lines = [line.strip() for line in text.split('\\n')]\n",
        "\n",
        "        return '\\n'.join(lines)\n",
        "\n",
        "    def split_into_chunks(self, text, max_chunk_size=4000):\n",
        "        \"\"\"\n",
        "        Splits the text into chunks for TTS processing, preserving sentence boundaries and natural pauses.\n",
        "\n",
        "        Args:\n",
        "            text (str): Text to split\n",
        "            max_chunk_size (int): Maximum size of each chunk\n",
        "\n",
        "        Returns:\n",
        "            list: List of text chunks\n",
        "        \"\"\"\n",
        "        import re\n",
        "        # Ensure all sentences end with proper punctuation\n",
        "        sentences = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
        "        # Remove empty sentences\n",
        "        sentences = [s.strip() for s in sentences if s.strip()]\n",
        "        chunks = []\n",
        "        current_chunk = \"\"\n",
        "        for sentence in sentences:\n",
        "            # Add a space after each sentence for natural pause\n",
        "            sentence_with_space = sentence if sentence.endswith(('.', '!', '?')) else sentence + '.'\n",
        "            sentence_with_space += ' '\n",
        "            if len(current_chunk) + len(sentence_with_space) > max_chunk_size:\n",
        "                if current_chunk:\n",
        "                    chunks.append(current_chunk.strip())\n",
        "                current_chunk = sentence_with_space\n",
        "            else:\n",
        "                current_chunk += sentence_with_space\n",
        "        if current_chunk:\n",
        "            chunks.append(current_chunk.strip())\n",
        "        return chunks\n",
        "\n",
        "\n",
        "# Function to install necessary dependencies in Colab.\n",
        "def instalar_dependencias():\n",
        "    import sys\n",
        "    !{sys.executable} -m pip install gtts pydub requests beautifulsoup4 pyttsx3\n",
        "    !apt-get install -y ffmpeg espeak\n",
        "\n",
        "# Install dependencies.\n",
        "instalar_dependencias()\n",
        "\n",
        "# Try importing pyttsx3 (offline TTS).\n",
        "try:\n",
        "    import pyttsx3\n",
        "    offline_tts_available = True\n",
        "except ImportError:\n",
        "    offline_tts_available = False\n",
        "\n",
        "# Function to get unit links from the module URL.\n",
        "def get_units_links(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    units = []\n",
        "    # Find all links with class 'unit-title'.\n",
        "    for a in soup.find_all('a', class_='unit-title', href=True):\n",
        "        full_url = requests.compat.urljoin(url, a['href'])\n",
        "        if full_url not in units:\n",
        "            units.append(full_url)\n",
        "    return units\n",
        "\n",
        "# Function to extract the title of the page.\n",
        "def extract_title(soup):\n",
        "    # Try different selectors to find the page title.\n",
        "    title_elem = soup.select_one('h1[data-bi-name=\"page-title\"], h1.title, h1, .page-title h1, [data-bi-name=\"page-title\"]')\n",
        "    if title_elem:\n",
        "        return title_elem.get_text().strip()\n",
        "    # Fallback to the HTML <title> tag.\n",
        "    title_tag = soup.find('title')\n",
        "    if title_tag:\n",
        "        return title_tag.get_text().strip()\n",
        "    return \"modulo\" # Default title if none found.\n",
        "\n",
        "# Function to convert text to audio using pyttsx3 (offline).\n",
        "def text_to_audio_offline(text, output_path, language='es', speed=1.0):\n",
        "    engine = pyttsx3.init()\n",
        "    # Configure language/voice if possible.\n",
        "    voices = engine.getProperty('voices')\n",
        "    selected_voice = None\n",
        "    for v in voices:\n",
        "        if language in v.id or language in v.name.lower():\n",
        "            selected_voice = v.id\n",
        "            break\n",
        "    if selected_voice:\n",
        "        engine.setProperty('voice', selected_voice)\n",
        "    engine.setProperty('rate', int(200 * speed)) # Set speech speed.\n",
        "    wav_path = output_path.replace('.mp3', '.wav')\n",
        "    engine.save_to_file(text, wav_path) # Save audio as WAV.\n",
        "    engine.runAndWait()\n",
        "    # Convert WAV to MP3.\n",
        "    audio = AudioSegment.from_wav(wav_path)\n",
        "    audio.export(output_path, format='mp3')\n",
        "    os.remove(wav_path) # Remove the temporary WAV file.\n",
        "\n",
        "# Main processing function.\n",
        "def procesar_modulo(url, language, speed):\n",
        "    units = get_units_links(url)\n",
        "    if not units:\n",
        "        print(\"No se encontraron unidades en el módulo.\")\n",
        "        return None\n",
        "    print(f\"{len(units)} unidades encontradas.\")\n",
        "    # Get module title for output directory name.\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    module_title = extract_title(soup)\n",
        "    safe_module_title = module_title.replace(' ', '_').replace('/', '_')\n",
        "    output_dir = f\"{safe_module_title}\"\n",
        "    os.makedirs(output_dir, exist_ok=True) # Create output directory.\n",
        "\n",
        "    # Process each unit.\n",
        "    for idx, unit_url in enumerate(units, 1):\n",
        "        print(f\"Procesando unidad {idx}: {unit_url}\")\n",
        "        # Limit to processing only the first unit for testing, remove in production.\n",
        "        # if idx > 1:\n",
        "        #     break\n",
        "        unit_resp = requests.get(unit_url)\n",
        "        unit_soup = BeautifulSoup(unit_resp.content, 'html.parser')\n",
        "        unit_title = extract_title(unit_soup)\n",
        "        safe_title = unit_title.replace(' ', '_').replace('/', '_')\n",
        "\n",
        "        # Extract main content text.\n",
        "        main_content = unit_soup.select_one('main, .content, [role=\"main\"], .main-content, article, .module-content')\n",
        "        if not main_content:\n",
        "            main_content = unit_soup\n",
        "        text = main_content.get_text(separator='\\n')\n",
        "\n",
        "        # Process and clean the extracted text.\n",
        "        processor = TextProcessor()\n",
        "        processed_text = processor.clean_and_structure(text)\n",
        "\n",
        "        # Convert processed text to audio using gTTS (online).\n",
        "        audio_path = os.path.join(output_dir, f\"unidad_{idx}-{safe_title}.mp3\")\n",
        "        tts = gTTS(text=processed_text, lang=language, slow=False)\n",
        "        tts.save(audio_path)\n",
        "        print(f\"Audio guardado: {audio_path}\")\n",
        "\n",
        "    return output_dir # Return the path to the output directory.\n",
        "\n",
        "# Execute the main processing function with input values.\n",
        "dir_modulo = procesar_modulo(url, language, speed)\n",
        "\n",
        "if dir_modulo:\n",
        "    # Define the path for the output zip file.\n",
        "    zip_path = f\"output.zip\"\n",
        "    # Create a zip file containing the audio files.\n",
        "    with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
        "        # Walk through the output directory and add files to the zip.\n",
        "        for root, _, files in os.walk(dir_modulo):\n",
        "            for file in files:\n",
        "                zipf.write(os.path.join(root, file), arcname=os.path.join(os.path.basename(dir_modulo), file))\n",
        "    print(f\"ZIP creado: {zip_path}\")\n",
        "    # Import the files module for downloading in Colab.\n",
        "    from google.colab import files\n",
        "    # Download the created zip file.\n",
        "    files.download(zip_path)\n",
        "else:\n",
        "    # Print a message if no module was generated.\n",
        "    print(\"No se generó ningún módulo para comprimir.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "cell_execution_strategy": "setup",
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}